-- vim: syn=pg noet ts=4 sw=0 sts=0

/* From: https://dev.to/kspeakman/comment/ld93

This exact point was brought up on a subsequent post about multi-tenant event store in the comments.

The problem is the auto-increment position, since it is not transactional. And to solve this problem, you have to manage the position separately so that it is transactional. This should not affect throughput to the same degree as locking the table.

Here are the structures that we use in our event store to solve the listener-missed-event problem.

*/

-- position counter
CREATE TABLE IF NOT EXISTS PositionCounter
(
	Position bigint NOT NULL
);

-- initialize the value
INSERT INTO PositionCounter VALUES (0);

-- prevent duplication on reinitialization
CREATE OR REPLACE RULE rule_positioncounter_noinsert AS
ON INSERT TO PositionCounter DO INSTEAD NOTHING;
-- prevent accidental deletion
CREATE OR REPLACE RULE rule_positioncounter_nodelete AS
ON DELETE TO PositionCounter DO INSTEAD NOTHING;

-- create function to increment/return position
DROP FUNCTION IF EXISTS NextPosition();
CREATE FUNCTION NextPosition() RETURNS bigint AS $$
	DECLARE
		nextPos bigint;
	BEGIN
		UPDATE PositionCounter
		   SET Position = Position + 1
		;
		SELECT INTO nextPos Position FROM PositionCounter;
		RETURN nextPos;
	END;
$$ LANGUAGE plpgsql;

-- events
CREATE TABLE IF NOT EXISTS Event
(
	Position bigint NOT NULL,
	StreamId uuid NOT NULL,
	Version int NOT NULL,
	Type text NOT NULL,
	Data jsonb,
	Meta jsonb NOT NULL,
	LogDate timestamptz NOT NULL DEFAULT now(),
	CONSTRAINT pk_event_position PRIMARY KEY (Position),
	CONSTRAINT uk_event_streamid_version UNIQUE (StreamId, Version)
);

-- Append only
CREATE OR REPLACE RULE rule_event_nodelete AS
ON DELETE TO Event DO INSTEAD NOTHING;
CREATE OR REPLACE RULE rule_event_noupdate AS
ON UPDATE TO Event DO INSTEAD NOTHING;

-- event notification
DROP TRIGGER IF EXISTS trg_NotifyEvent ON Event;
DROP FUNCTION IF EXISTS NotifyEvent();

CREATE FUNCTION NotifyEvent() RETURNS trigger AS $$

	DECLARE
		payload text;

	BEGIN
		-- { position }/{ stream id }/{ version }/{ event type }
		SELECT CONCAT_WS( '/'
						, NEW.Position
						, REPLACE(CAST(NEW.StreamId AS text), '-', '')
						, NEW.Version
						, NEW.Type
						)
			INTO payload
		;

		-- using lower case channel name or else LISTEN would require quoted identifier.
		PERFORM pg_notify('eventrecorded', payload);

		RETURN NULL;

	END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_NotifyEvent
	AFTER INSERT ON Event
	FOR EACH ROW
	EXECUTE PROCEDURE NotifyEvent()
;


/*

Then when you write events to the table, you set the Position to NextPosition().

*/


INSERT
  INTO Event
	 ( Position
	 , StreamId
	 , Version
	 , Type
	 , Data
	 , Meta
	 )
VALUES
	 ( NextPosition()
	 , @StreamId
	 , @Version
	 , @Type
	 , @Data
	 , @Meta
	 )
;


/*

Side note: You are probably aware of this and consciously made the trade-off, but just in case: writing to multiple streams in a transaction brings some significant restrictions on how the system can evolve in the future. It's fine if you don't plan to scale past a single db node, or can work if you are partitioning db nodes by tenant or some other key. But it does narrow your options in general.

*/

